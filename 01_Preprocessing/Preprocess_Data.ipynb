{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Training & Test Data\n",
    "Preprocess labeled data.\n",
    "1. Collapse labels\n",
    "2. Rename labels\n",
    "3. Convert rows with no labels to \"not infection\"\n",
    "4. Fill NAs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kevinyuan/EHR-Indication-Processing/01_Preprocessing\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading consensus labels:\n",
      "consensus_labels_2022-11-02\n",
      "consensus_labels_2023-04-11\n",
      "consensus_labels_2023-08-14_1\n",
      "consensus_labels_2023-08-14_2\n",
      "\n",
      "Reading unlabelled data:\n",
      "Train_Set_4000\n",
      "Test_Set_2000\n",
      "Test_Set_2000\n",
      "\n",
      "Label data size:  (5615, 15)\n"
     ]
    }
   ],
   "source": [
    "# --- Set Paths\n",
    "# Set base data path\n",
    "base_data_path = Path(\"../00_Data\")\n",
    "\n",
    "assert base_data_path.is_dir(),\\\n",
    "  f\"{base_data_path} either doesn't exist or is not a directory.\"\n",
    "\n",
    "# Set output data path\n",
    "output_path = base_data_path/\"publication_ready\"\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Consensus labels path\n",
    "consensus_labels_path = base_data_path/\"consensus_labels\"\n",
    "\n",
    "# Data Sets path\n",
    "data_sets_path = base_data_path/\"data_sets\"\n",
    "\n",
    "# --- Import data\n",
    "# Read all label CSV files starting with \"consensus_labels_*.csv\"\n",
    "consensus_label_list = []\n",
    "\n",
    "print(\"Reading consensus labels:\")\n",
    "for file in sorted(consensus_labels_path.glob(\"consensus_labels_*.csv\")):\n",
    "    print(file.stem)\n",
    "    consensus_label_list.append(pd.read_csv(\n",
    "      file,\n",
    "      dtype={\"Indication\": str},\n",
    "      keep_default_na=False,\n",
    "      na_values=[\"NA\"],\n",
    "    ))\n",
    "print()\n",
    "\n",
    "consensus_labels_raw = pd.concat(consensus_label_list, ignore_index=True)\n",
    "\n",
    "# Read the Unlabelled Data\n",
    "unlabelled_data_dict = {\n",
    "  \"oxford_training_unlabelled_df\": data_sets_path/'Oxford/Train_Set_4000.csv',\n",
    "  \"oxford_testing_unlabelled_df\": data_sets_path/'Oxford/Test_Set_2000.csv',\n",
    "  \"banbury_testing_unlabelled_df\": data_sets_path/'Banbury/Test_Set_2000.csv',\n",
    "}\n",
    "\n",
    "print(\"Reading unlabelled data:\")\n",
    "for key, value in unlabelled_data_dict.items():\n",
    "    print(value.stem)\n",
    "    globals()[key] = pd.read_csv(\n",
    "      value,\n",
    "      dtype={\"Indication\": str},\n",
    "      keep_default_na=False,\n",
    "      na_values=None,\n",
    "    )\n",
    "print()\n",
    "\n",
    "# Check data size\n",
    "print(\"Label data size: \", consensus_labels_raw.shape)\n",
    "# print(\"Test missing data size: \", test_missing_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indication</th>\n",
       "      <th>urinary</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>neurological</th>\n",
       "      <th>skin_soft_tissue</th>\n",
       "      <th>ent</th>\n",
       "      <th>orthopaedic</th>\n",
       "      <th>other</th>\n",
       "      <th>no_specific_source</th>\n",
       "      <th>prophylaxis</th>\n",
       "      <th>procedural</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>viral</th>\n",
       "      <th>uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:lrti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>? abdo infection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>? abdo sepsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>? abdominal collection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5610</th>\n",
       "      <td>uti w catheter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>uti/ cellulitis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5612</th>\n",
       "      <td>uti/chest dlerium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5613</th>\n",
       "      <td>uti/non specific infectio</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>uto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5615 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Indication  urinary  respiratory  abdominal  \\\n",
       "0                         :lrti      NaN          1.0        NaN   \n",
       "1                             ?      NaN          NaN        NaN   \n",
       "2              ? abdo infection      NaN          NaN        1.0   \n",
       "3                 ? abdo sepsis      NaN          NaN        1.0   \n",
       "4        ? abdominal collection      NaN          NaN        1.0   \n",
       "...                         ...      ...          ...        ...   \n",
       "5610             uti w catheter      1.0          0.0        0.0   \n",
       "5611            uti/ cellulitis      1.0          0.0        0.0   \n",
       "5612          uti/chest dlerium      1.0          1.0        0.0   \n",
       "5613  uti/non specific infectio      1.0          0.0        0.0   \n",
       "5614                        uto      1.0          0.0        0.0   \n",
       "\n",
       "      neurological  skin_soft_tissue  ent  orthopaedic  other  \\\n",
       "0              NaN               NaN  NaN          NaN    NaN   \n",
       "1              NaN               NaN  NaN          NaN    NaN   \n",
       "2              NaN               NaN  NaN          NaN    NaN   \n",
       "3              NaN               NaN  NaN          NaN    NaN   \n",
       "4              NaN               NaN  NaN          NaN    NaN   \n",
       "...            ...               ...  ...          ...    ...   \n",
       "5610           0.0               0.0  0.0          0.0    0.0   \n",
       "5611           0.0               1.0  0.0          0.0    0.0   \n",
       "5612           0.0               0.0  0.0          0.0    0.0   \n",
       "5613           0.0               0.0  0.0          0.0    0.0   \n",
       "5614           0.0               0.0  0.0          0.0    0.0   \n",
       "\n",
       "      no_specific_source  prophylaxis  procedural  immunosuppression  viral  \\\n",
       "0                    NaN          NaN         NaN                NaN    NaN   \n",
       "1                    NaN          NaN         NaN                NaN    NaN   \n",
       "2                    NaN          NaN         NaN                NaN    NaN   \n",
       "3                    NaN          NaN         NaN                NaN    NaN   \n",
       "4                    NaN          NaN         NaN                NaN    NaN   \n",
       "...                  ...          ...         ...                ...    ...   \n",
       "5610                 0.0          0.0         1.0                0.0    0.0   \n",
       "5611                 0.0          0.0         0.0                0.0    0.0   \n",
       "5612                 0.0          0.0         0.0                0.0    0.0   \n",
       "5613                 0.0          0.0         0.0                0.0    0.0   \n",
       "5614                 0.0          0.0         0.0                0.0    0.0   \n",
       "\n",
       "      uncertainty  \n",
       "0             NaN  \n",
       "1             1.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  \n",
       "...           ...  \n",
       "5610          0.0  \n",
       "5611          1.0  \n",
       "5612          1.0  \n",
       "5613          1.0  \n",
       "5614          0.0  \n",
       "\n",
       "[5615 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_labels_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Collapse labels & convert NAs to 0s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Datasets\n",
    "Unify the labels, collapse some categories, convert to the same datatype.\n",
    "\n",
    "Then apply labels to our data sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unify labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to collapse labels & perform some cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_labels(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # -- Collapse [\"prophylaxis\", \"procedural\"] into \"prophylaxis\", and\n",
    "    # [\"immunosuppression\", \"viral\"] into \"not_infection\"\n",
    "    input_df[\"prophylaxis\"] = input_df[[\"prophylaxis\", \"procedural\"]].any(axis=1) * 1\n",
    "    input_df[\"not_informative\"] = input_df[['viral']].any(axis=1) * 1\n",
    "\n",
    "    # Drop the collapsed columns\n",
    "    labels_to_drop = ['procedural', 'viral']\n",
    "    input_df = input_df.drop(columns = labels_to_drop)\n",
    "\n",
    "    # -- Clean column names & columns\n",
    "    # Rename \"other\" column to \"other_specific\"\n",
    "    input_df = input_df.rename(columns={\"other\": \"other_specific\"})\n",
    "\n",
    "    # Drop \"immunosuppression\" column\n",
    "    input_df = input_df.drop(columns = ['immunosuppression'])\n",
    "\n",
    "    # -- Convert all entries with no specified indication to \"not_informative\"\n",
    "    # Get mask of rows with no label\n",
    "    df_mask = ~input_df.drop(columns=[\"Indication\", \"uncertainty\"]).any(axis=1)\n",
    "    # Apply binary or to \"not_informative\" column and mask\n",
    "    input_df[\"not_informative\"] = input_df[\"not_informative\"] | (df_mask * 1)\n",
    "\n",
    "    print(\"Number of entries with no label converted to 'not_informative':\",\n",
    "        df_mask.sum())\n",
    "    print(\"Added \\\"not_informative\\\" indications:\\n\", input_df[df_mask].Indication)\n",
    "    \n",
    "    # -- Unify Data Types\n",
    "    # Fill NaN with 0\n",
    "    input_df = input_df.fillna(0)\n",
    "\n",
    "    # Convert numbers to integers\n",
    "    input_num_cols = input_df.select_dtypes(np.number)\n",
    "    input_df[input_num_cols.columns] = input_num_cols.astype('Int64')\n",
    "\n",
    "\n",
    "    return input_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the training data and collapse labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with no label converted to 'not_informative': 4\n",
      "Added \"not_informative\" indications:\n",
      " 1                         ?\n",
      "2414                    n/a\n",
      "2782    port site infection\n",
      "3318         rif collection\n",
      "Name: Indication, dtype: object\n",
      "\n",
      "\n",
      "Check consensus labels dtypes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Indication            object\n",
       "urinary                Int64\n",
       "respiratory            Int64\n",
       "abdominal              Int64\n",
       "neurological           Int64\n",
       "skin_soft_tissue       Int64\n",
       "ent                    Int64\n",
       "orthopaedic            Int64\n",
       "other_specific         Int64\n",
       "no_specific_source     Int64\n",
       "prophylaxis            Int64\n",
       "uncertainty            Int64\n",
       "not_informative        Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"n\" column & collapse columns\n",
    "consensus_labels = collapse_labels(consensus_labels_raw)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check data types\n",
    "print(\"Check consensus labels dtypes:\")\n",
    "consensus_labels.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no duplicate entries within the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indication</th>\n",
       "      <th>urinary</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>neurological</th>\n",
       "      <th>skin_soft_tissue</th>\n",
       "      <th>ent</th>\n",
       "      <th>orthopaedic</th>\n",
       "      <th>other_specific</th>\n",
       "      <th>no_specific_source</th>\n",
       "      <th>prophylaxis</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>not_informative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Indication, urinary, respiratory, abdominal, neurological, skin_soft_tissue, ent, orthopaedic, other_specific, no_specific_source, prophylaxis, uncertainty, not_informative]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get non unique rows (i.e. duplicate rows) by Indication and sort rows by Indication\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(consensus_labels[consensus_labels.duplicated(subset=[\"Indication\"], keep=False)].sort_values(by=[\"Indication\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Oxford Data\n",
    "Contains the `traing_4000` and `test_2000_oxford` data et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join back with the original data, keep only the \"Indication\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NA values:\n",
      "Series([], Name: Indication, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Join test_unlabeled_df with complete_labels\n",
    "oxford_training_df = oxford_training_unlabelled_df[[\"Indication\"]]\n",
    "\n",
    "oxford_training_df = oxford_training_df.\\\n",
    "    join(\n",
    "        consensus_labels.set_index(\"Indication\"),\n",
    "        on=\"Indication\", \n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\")\n",
    "\n",
    "# Verify that we don't have any missing entries\n",
    "missing_rows = oxford_training_df[oxford_training_df.isna().any(axis=1)]\n",
    "print(\"Rows with NA values:\")\n",
    "print(missing_rows.Indication)\n",
    "\n",
    "assert missing_rows.shape[0] == 0, \"There are unlabelled entries in the training data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Join back with the original test data, keep only a subset of the columns neede to identify the prescription.\n",
    "\n",
    "For publication strip the identifiable data & only keep the indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NA values:\n",
      "Series([], Name: Indication, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "oxford_testing_df = oxford_testing_unlabelled_df[[\"PrescriptionID\", \"Indication\"]]\n",
    "\n",
    "oxford_testing_df = oxford_testing_df.\\\n",
    "    join(\n",
    "        consensus_labels.set_index(\"Indication\"),\n",
    "        on=\"Indication\", \n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\")\n",
    "\n",
    "# Verify that we don't have any missing entries\n",
    "missing_rows = oxford_testing_df[oxford_testing_df.isna().any(axis=1)]\n",
    "print(\"Rows with NA values:\")\n",
    "print(missing_rows.Indication)\n",
    "\n",
    "assert missing_rows.shape[0] == 0, \"There are unlabelled entries in the training data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banbury Data\n",
    "The external test set site Banbury only has one test set.\n",
    "\n",
    "Join back with the original test data, keep only a subset of the columns neede to identify the prescription.\n",
    "\n",
    "For publication strip the identifiable data & only keep the indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NA values:\n",
      "Series([], Name: Indication, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "banbury_testing_df = banbury_testing_unlabelled_df[[\"PrescriptionID\", \"Indication\"]]\n",
    "\n",
    "banbury_testing_df = banbury_testing_df.\\\n",
    "    join(\n",
    "        consensus_labels.set_index(\"Indication\"),\n",
    "        on=\"Indication\", \n",
    "        how=\"left\",\n",
    "        validate=\"many_to_one\")\n",
    "\n",
    "# Verify that we don't have any missing entries\n",
    "missing_rows = banbury_testing_df[banbury_testing_df.isna().any(axis=1)]\n",
    "print(\"Rows with NA values:\")\n",
    "print(missing_rows.Indication)\n",
    "\n",
    "assert missing_rows.shape[0] == 0, \"There are unlabelled entries in the training data.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp for the file names\n",
    "date_stamp = pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# All conensus labels\n",
    "consensus_labels.to_csv(output_path/f\"consensus_labels_full_{date_stamp}.csv\", index=False)\n",
    "\n",
    "# Training data\n",
    "oxford_training_df.to_csv(output_path/f\"training_oxford_{date_stamp}.csv\", index=False)\n",
    "oxford_testing_df.to_csv(output_path/f\"testing_oxford_{date_stamp}.csv\", index=False)\n",
    "\n",
    "# Test data\n",
    "banbury_testing_df.to_csv(output_path/f\"testing_banbury_{date_stamp}.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
