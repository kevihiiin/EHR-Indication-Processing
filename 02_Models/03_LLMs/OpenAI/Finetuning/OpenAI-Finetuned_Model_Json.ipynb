{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Models - Tinetuned model\n",
    "Test the classification perfomance of OpenAI LLMs.\n",
    "\n",
    "Test cases will include:\n",
    "- **Zero Shot Models**\n",
    "- Embedding + XGBoost (or Cosine Similarity)\n",
    "- Finetuned model\n",
    "\n",
    "This notebook will attempt to create achieve multi-class classification by leaveraging the JSON output functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- [x] The new preview model supports setting a seed to make \"reproducable\" runs\n",
    "- [ ] Run model multiple rounds and check reproducability\n",
    "- [x] Use .env files to set API keys\n",
    "- [x] Implement token counter and optimise supplied prompts\n",
    "- [x] Return number of used promts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Study Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries\n",
    "Load libraries and the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: /home/kevin/DPhil/Projects/EHR-Indication-Processing/02_Models/03_LLMs/OpenAI/Finetuning\n"
     ]
    }
   ],
   "source": [
    "# --- Load libraries\n",
    "# Standard libraries\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import jinja2\n",
    "\n",
    "# Typing\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# Misc\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# DS libs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ML libs\n",
    "from openai import OpenAI\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- Specify logging level\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# --- Check the environment and load API key\n",
    "print(\"Current work directory:\", Path.cwd())\n",
    "\n",
    "# Load API key (DO NOT HARDCODE)\n",
    "load_dotenv()\n",
    "\n",
    "if _SECRET_KEY := os.getenv(\"OPENAI_API_KEY\"):\n",
    "    logging.debug(\"API key found.\")\n",
    "    client = OpenAI(\n",
    "        # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "        api_key=_SECRET_KEY\n",
    "    )\n",
    "else:\n",
    "    logging.error(\"API key not found. Please set the environment variable OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Study Parameters\n",
    "Data paths and model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "model_selection = \"GPT3.5 Turbo\"  # \"Davinci\" or \"Curie\" or \"Babbage\" or \"Ada\"\n",
    "\n",
    "model_dict = {\n",
    "    \"GPT4\": \"gpt-4-0125-preview\",\n",
    "    # Only the following are made for chats\n",
    "    \"GPT3.5 Turbo\": \"gpt-3.5-turbo-0125\",\n",
    "    # Only the following supports pure completion and text substitution\n",
    "    \"GPT3.5 Davinci\": \"text-davinci-003\",\n",
    "    # Only the following support finetuning, decreasing in performance and cost\n",
    "    \"Davinci\": \"davinci\",\n",
    "    \"Curie\": \"curie\",\n",
    "    \"Babbage\": \"babbage\",\n",
    "    \"Ada\": \"ada\",    \n",
    "}\n",
    "\n",
    "# --- Misc settings\n",
    "# Model names\n",
    "model_name_display = model_selection\n",
    "model_openai_id = model_dict[model_selection]  # OpenAI name/identifier\n",
    "\n",
    "# --- Paths\n",
    "# Base data path\n",
    "base_data_path = Path(\"../../../../00_Data/\")\n",
    "# Dataset Path (training, testing, etc.)\n",
    "dataset_path =  base_data_path / \"publication_ready\"\n",
    "# Export Path (model checkpoints, predictions, etc.)\n",
    "export_path = base_data_path / \"model_output\" / f\"{model_openai_id.capitalize()}-Finetuned-Json\"\n",
    "# Finetuning data\n",
    "ft_data_path = export_path / \"finetuning_data\"\n",
    "\n",
    "\n",
    "assert base_data_path.is_dir(),\\\n",
    "  f\"{base_data_path} either doesn't exist or is not a directory.\"\n",
    "export_path.mkdir(exist_ok=True)\n",
    "ft_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and clean data\n",
    "Import the test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size overview:\n",
      "- Training set: 3400\n",
      "- Evaluation set: 600\n",
      "- Testing Oxford set: 2000\n",
      "- Testing Banbury set: 2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import data --> upload into \"Files\" on the left-hand panel\n",
    "train_eval_df = pd.read_csv(\n",
    "    dataset_path / 'training_oxford_2023-08-23.csv',\n",
    "    dtype={\"Indication\": str},\n",
    "    keep_default_na=False,\n",
    "    na_values=[\"NA\"],\n",
    ")\n",
    "\n",
    "test_oxford_df = pd.read_csv(\n",
    "    dataset_path / 'testing_oxford_2023-08-23.csv',\n",
    "    dtype={\"Indication\": str},\n",
    "    keep_default_na=False,\n",
    "    na_values=[\"NA\"],\n",
    ")\n",
    "\n",
    "test_banbury_df = pd.read_csv(\n",
    "    dataset_path / 'testing_banbury_2023-08-23.csv',\n",
    "    dtype={\"Indication\": str},\n",
    "    keep_default_na=False,\n",
    "    na_values=[\"NA\"],\n",
    ")\n",
    "\n",
    "# --- Split into train and eval\n",
    "train_df, eval_df = train_test_split(\n",
    "    train_eval_df, \n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    shuffle=True)\n",
    "\n",
    "print(\"Data set size overview:\")\n",
    "print(f\"- Training set: {train_df.shape[0]}\")\n",
    "print(f\"- Evaluation set: {eval_df.shape[0]}\")\n",
    "print(f\"- Testing Oxford set: {test_oxford_df.shape[0]}\")\n",
    "print(f\"- Testing Banbury set: {test_banbury_df.shape[0]}\")\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define labels and mappers\n",
    "Convert labels to numbers and get prettier labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Urinary',\n",
       " 'Respiratory',\n",
       " 'Abdominal',\n",
       " 'Neurological',\n",
       " 'Skin Soft Tissue',\n",
       " 'ENT',\n",
       " 'Orthopaedic',\n",
       " 'Other Specific',\n",
       " 'No Specific Source',\n",
       " 'Prophylaxis',\n",
       " 'Uncertainty',\n",
       " 'Not Informative']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels\n",
    "labels = [label for label in train_df.columns if label not in [\"Indication\"]]\n",
    "labels_pretty = []\n",
    "for label in labels:\n",
    "    if label == \"ent\":\n",
    "        labels_pretty.append(\"ENT\")\n",
    "        continue\n",
    "    labels_pretty.append(\" \".join(word.capitalize() for word in label.split(\"_\")))\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels2labels_pretty = {old:pretty for old, pretty in zip(labels, labels_pretty)}\n",
    "\n",
    "labels_pretty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "\n",
    "- Prettyfy the column labels (rename them)\n",
    "- Get a subset of the data for experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [train_df, eval_df, test_oxford_df, test_banbury_df]:\n",
    "    dataset.rename(columns=labels2labels_pretty, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now get a subset of the training data:\n",
    "- Extract some indications as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subsample = train_df.sample(n=100)\n",
    "test_subsample_indications = test_subsample.Indication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Model\n",
    "Create a good query to use for Zero Shot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_completion(client, system_prompt, user_prompt, model_openai_id, max_tokens=100, seed=42):\n",
    "    \"\"\"Sends the promt to the OpenAI API and returns the response.\n",
    "    Specify parameters for the model in the function call.\n",
    "    \"\"\"\n",
    "    # --- Fetch Chat Completion\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,  # Set lower temperature (default 0)\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=1,  # Return only the most likely completion (save tokens)\n",
    "        frequency_penalty=0,  # Default of 0, repeating sequences are ok and wanted\n",
    "        presence_penalty=0,  # Set to lower value to decrease the likelyhood if the model inveting new words/categories\n",
    "        model=model_openai_id,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=seed,  # Set seed for reproducibility (check the API documentation for more details)\n",
    "        #logit_bias  # Force the model to only reply with the specified labels?\n",
    "        #logprobs  # Can it be used for evaluation?\n",
    "    )\n",
    "    # --- Process the response\n",
    "    # -- Content\n",
    "    # There will only be one completion given the parameter `top_p=1`\n",
    "    chat_completion_content = chat_completion.choices[0]\n",
    "\n",
    "    # Check whether the completion was truncated\n",
    "    if (finish_reason := chat_completion_content.finish_reason) != \"stop\":\n",
    "        logging.warning(f\"Completion was truncated. Finish reason: {finish_reason}\")\n",
    "    \n",
    "    chat_completion_message = chat_completion_content.message.content\n",
    "\n",
    "    # -- Metadata\n",
    "    # Gather general metadata\n",
    "    chat_completion_metadata = {\n",
    "        \"model\": chat_completion.model,\n",
    "        \"created\": chat_completion.created,\n",
    "        \"finish_reason\": finish_reason,\n",
    "        \"system_fingerprint\": chat_completion.system_fingerprint,\n",
    "    }\n",
    "\n",
    "    # Get usage metadata\n",
    "    chat_completion_usage = {\n",
    "        \"completion_tokens\": chat_completion.usage.completion_tokens,\n",
    "        \"prompt_tokens\": chat_completion.usage.prompt_tokens,\n",
    "        \"total_tokens\": chat_completion.usage.total_tokens,\n",
    "    }\n",
    "    \n",
    "    return chat_completion_message, chat_completion_metadata, chat_completion_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request formatting\n",
    "The new API (November 2023) allows/requests to specify three messages:\n",
    "1. System Prompt: Task description\n",
    "2. User Prompt User input\n",
    "3. Assistant Prompt: Model response\n",
    "\n",
    "The system prompt is the same for each request (static).\n",
    "The user prompt is dynamically generated and reformats the input into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system_template_string = \"\"\"You are a helpful and precise UK medical expert. You have been given a list of indications describing why antibiotics were prescribed to patients in a hospital and asked to label these indications into categories.\n",
    "You can only choose from the following categories: {% for category in categories %}\"{{ category }}\"{% if not loop.last %}, {% endif %}{% endfor %}.\n",
    "Multiple categories are allowed.\n",
    "\"ENT\" stands for \"Ear Nose and Throat\".\n",
    "\"Uncertainty\" refers to uncertainty specified by the clinician (e.g. \"?\" or multiple unrelated sources).\n",
    "\"No Spefic Source\" means a source can be inferred but it's not specific (e.g. just the word \"sepsis\" or \"infection\").\n",
    "\"Not Informative\" means the field does not reveal the source, is a viral infection or is unrelated to bacterial infections. When answering the question, please return a JSON.\n",
    "\"\"\"\n",
    "\n",
    "prompt_user_template_string = \\\n",
    "\"\"\"\n",
    "Return a JSON with the categories (multiple allowed) for each indication:\n",
    "{\n",
    "{% for indication in indications -%}\n",
    "\"{{ indication }}\":[],\n",
    "{% endfor %}\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Build the template\n",
    "environment = jinja2.Environment()\n",
    "prompt_user_template = environment.from_string(prompt_user_template_string)\n",
    "prompt_system_template = environment.from_string(prompt_system_template_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render template with example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt:\n",
      "You are a helpful and precise UK medical expert. You have been given a list of indications describing why antibiotics were prescribed to patients in a hospital and asked to label these indications into categories.\n",
      "You can only choose from the following categories: \"Urinary\", \"Respiratory\", \"Abdominal\", \"Neurological\", \"Skin Soft Tissue\", \"ENT\", \"Orthopaedic\", \"Other Specific\", \"No Specific Source\", \"Prophylaxis\", \"Uncertainty\", \"Not Informative\".\n",
      "Multiple categories are allowed.\n",
      "\"ENT\" stands for \"Ear Nose and Throat\".\n",
      "\"Uncertainty\" refers to uncertainty specified by the clinician (e.g. \"?\" or multiple unrelated sources).\n",
      "\"No Spefic Source\" means a source can be inferred but it's not specific (e.g. just the word \"sepsis\" or \"infection\").\n",
      "\"Not Informative\" means the field does not reveal the source, is a viral infection or is unrelated to bacterial infections. When answering the question, please return a JSON.\n",
      "User Prompt:\n",
      "\n",
      "Return a JSON with the categories (multiple allowed) for each indication:\n",
      "{\n",
      "\"suspected chorioamnioniti\":[],\n",
      "\"supraglottitis\":[],\n",
      "\"cat bite\":[],\n",
      "\"copd exacerbation\":[],\n",
      "\"uti post op\":[],\n",
      "\"wound prophylaxis\":[],\n",
      "\"positive culture\":[],\n",
      "\"surg prophylaxis\":[],\n",
      "\"raised crp\":[],\n",
      "\"bone infe\":[],\n",
      "\"vasculitis\":[],\n",
      "\"cf infection\":[],\n",
      "\"chest infection post op\":[],\n",
      "\"pcp proph\":[],\n",
      "\"chest/urine\":[],\n",
      "\"infected knee joint\":[],\n",
      "\"aau\":[],\n",
      "\"infection ?urinary\":[],\n",
      "\"aspergillosis\":[],\n",
      "\"infected ulcers\":[],\n",
      "\"cellulitis ?nec fasc\":[],\n",
      "\"wound site infection\":[],\n",
      "\"esbl e coli\":[],\n",
      "\"orbital decompression\":[],\n",
      "\"? bone infection\":[],\n",
      "\"post op bleed\":[],\n",
      "\"post-op plan\":[],\n",
      "\"prophylaxis on chemo\":[],\n",
      "\"for latp biopsy\":[],\n",
      "\"post i+d\":[],\n",
      "\"psc\":[],\n",
      "\"bowel transplant\":[],\n",
      "\"hosp acquired pneumonia\":[],\n",
      "\"right heel ulcer\":[],\n",
      "\"?iecopd\":[],\n",
      "\"splenectomy prophylaxis\":[],\n",
      "\"?c. diff\":[],\n",
      "\"pcp pneumonia\":[],\n",
      "\"surgical infection\":[],\n",
      "\"lung infection\":[],\n",
      "\"choleycystitis\":[],\n",
      "\"pre-septal cellulitis\":[],\n",
      "\"uti prophylaxis\":[],\n",
      "\"spinal metalwork infectio\":[],\n",
      "\"foot cellulitis\":[],\n",
      "\"pericarditis\":[],\n",
      "\"dental absces\":[],\n",
      "\"urine/chest infection\":[],\n",
      "\"stem cell transplant\":[],\n",
      "\"itching\":[],\n",
      "\"penile infection\":[],\n",
      "\"worsening cap\":[],\n",
      "\"?rickettsia\":[],\n",
      "\"psa prophylaxis\":[],\n",
      "\"hand infection\":[],\n",
      "\"? meningitis\":[],\n",
      "\"renal abscess\":[],\n",
      "\"post allograft\":[],\n",
      "\"wound infection prophylax\":[],\n",
      "\"? cholecystitis\":[],\n",
      "\"crt-p\":[],\n",
      "\"necrotising fascitis\":[],\n",
      "\"uti/lrti\":[],\n",
      "\"prokinetics\":[],\n",
      "\"life long\":[],\n",
      "\"intra abdo\":[],\n",
      "\"abscess + cellulitis\":[],\n",
      "\"possible empyema\":[],\n",
      "\"citrobacter uti\":[],\n",
      "\"febrile post chemo\":[],\n",
      "\"myeloma prophylaxis\":[],\n",
      "\"?necrotising fasciitis\":[],\n",
      "\"chest\":[],\n",
      "\"diverticulits\":[],\n",
      "\"r hand cellulitis\":[],\n",
      "\"superficial wound infecti\":[],\n",
      "\"complex tear\":[],\n",
      "\"tonsillitits\":[],\n",
      "\"post operation\":[],\n",
      "\"ie asthma\":[],\n",
      "\"subphrenic collection\":[],\n",
      "\"neck cellulitis\":[],\n",
      "\"?hsv encephalitis\":[],\n",
      "\"pre-thoracoscopy\":[],\n",
      "\"srom>24hrs\":[],\n",
      "\"?covid\":[],\n",
      "\"oral candida\":[],\n",
      "\"?ventriculitis\":[],\n",
      "\"sepsis unkown origin\":[],\n",
      "\"enterococcus\":[],\n",
      "\"post-op cover\":[],\n",
      "\"superficial skin infectio\":[],\n",
      "\"cellulitis/uti\":[],\n",
      "\"forearm abscess\":[],\n",
      "\"cat bite infection\":[],\n",
      "\"infeciton\":[],\n",
      "\"extended prophylaxis\":[],\n",
      "\"temp spike\":[],\n",
      "\"intraabdominal infection\":[],\n",
      "\"parapneumonic effusion\":[],\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Render and display the tempaltes\n",
    "prompt_system = prompt_system_template.render(categories=labels_pretty)\n",
    "prompt_user = prompt_user_template.render(indications=test_subsample_indications, categories=labels_pretty)\n",
    "\n",
    "print(\"System Prompt:\")\n",
    "print(prompt_system)\n",
    "print(\"User Prompt:\")\n",
    "print(prompt_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the JSON return message into a indicator dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_message_to_df(return_msg_str):\n",
    "    # Convert the string to a dict/json\n",
    "    return_msg_json = json.loads(return_msg_str)\n",
    "\n",
    "    # Convert the dict to a DataFrame\n",
    "    return_msg_df = pd.DataFrame.from_dict(return_msg_json, orient='index')\n",
    "    input_index = return_msg_df.index\n",
    "\n",
    "    # Apply get_dummies and sum along the columns axis, to make indicator matrix\n",
    "    return_msg_df = pd.get_dummies(return_msg_df.stack().reset_index(level=1, drop=True))\\\n",
    "        .groupby(level=0, sort=False)\\\n",
    "        .sum()\\\n",
    "        .reindex(input_index)\n",
    "\n",
    "    return return_msg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns and sort order for the true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_categories = [category for category in labels_pretty if category not in [\"No Specific Source\", \"Not Informative\"]]\n",
    "metric_categories = [category for category in labels_pretty if category not in [\"Not Informative\"]]\n",
    "\n",
    "def score_response(pred_y, true_y, metric_categories, index_key=None):\n",
    "    # Reindex (rearrange) if specifided\n",
    "    if index_key:\n",
    "        # Set index\n",
    "        true_y = true_y.set_index(index_key)\n",
    "        pred_y = pred_y.set_index(index_key)\n",
    "        # Rearrange\n",
    "        pred_y = pred_y.reindex(true_y.index)\n",
    "\n",
    "    # --- Get true labels\n",
    "    y_test_pred = pred_y[metric_categories]\n",
    "    y_test_true = true_y[metric_categories]\n",
    "    # --- Calculate per-class metrics (F1 Score and ROC AUC)\n",
    "    scores_per_class = {}\n",
    "    scores_per_class[\"F1-Score\"] = f1_score(y_true=y_test_true, y_pred=y_test_pred, average=None)\n",
    "\n",
    "    scores_per_class = pd.DataFrame.from_dict(scores_per_class,orient='index', columns=metric_categories)\n",
    "\n",
    "    pd.set_option('display.precision', 2)\n",
    "\n",
    "    # --- Calculate overall averages (F1 Score and ROC AUC)\n",
    "    scores_average = {}\n",
    "    averaging_method = \"weighted\"\n",
    "    scores_average[\"F1-Score\"] = f1_score(y_true=y_test_true, y_pred=y_test_pred, average=averaging_method)\n",
    "    return scores_average, scores_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "Finetune a GPT variant based on the training data.\n",
    "\n",
    "- Format the data to be suitable for finetuning\n",
    "- Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'? bone infection': ['Orthopaedic', 'Uncertainty'],\n",
       " '? cholecystitis': ['Abdominal', 'Uncertainty'],\n",
       " '? meningitis': ['Neurological', 'Uncertainty'],\n",
       " '?c. diff': ['Abdominal', 'Uncertainty'],\n",
       " '?covid': ['No Specific Source', 'Uncertainty', 'Not Informative'],\n",
       " '?hsv encephalitis': ['Neurological', 'Uncertainty', 'Not Informative'],\n",
       " '?iecopd': ['Respiratory', 'Uncertainty'],\n",
       " '?necrotising fasciitis': ['Skin Soft Tissue', 'Uncertainty'],\n",
       " '?rickettsia': ['No Specific Source', 'Uncertainty'],\n",
       " '?ventriculitis': ['Neurological', 'Uncertainty'],\n",
       " 'aau': ['No Specific Source'],\n",
       " 'abscess + cellulitis': ['Skin Soft Tissue'],\n",
       " 'aspergillosis': ['No Specific Source'],\n",
       " 'bone infe': ['Orthopaedic'],\n",
       " 'bowel transplant': ['Abdominal', 'Prophylaxis'],\n",
       " 'cat bite': ['Skin Soft Tissue'],\n",
       " 'cat bite infection': ['Skin Soft Tissue'],\n",
       " 'cellulitis ?nec fasc': ['Skin Soft Tissue', 'Uncertainty'],\n",
       " 'cellulitis/uti': ['Urinary', 'Skin Soft Tissue', 'Uncertainty'],\n",
       " 'cf infection': ['Respiratory'],\n",
       " 'chest': ['Respiratory'],\n",
       " 'chest infection post op': ['Respiratory', 'Prophylaxis'],\n",
       " 'chest/urine': ['Urinary', 'Respiratory', 'Uncertainty'],\n",
       " 'choleycystitis': ['Abdominal'],\n",
       " 'citrobacter uti': ['Urinary'],\n",
       " 'complex tear': ['Skin Soft Tissue'],\n",
       " 'copd exacerbation': ['Respiratory'],\n",
       " 'crt-p': ['Other Specific', 'Prophylaxis'],\n",
       " 'dental absces': ['Other Specific'],\n",
       " 'diverticulits': ['Abdominal'],\n",
       " 'enterococcus': ['No Specific Source'],\n",
       " 'esbl e coli': ['No Specific Source'],\n",
       " 'extended prophylaxis': ['No Specific Source', 'Prophylaxis'],\n",
       " 'febrile post chemo': ['No Specific Source'],\n",
       " 'foot cellulitis': ['Skin Soft Tissue'],\n",
       " 'for latp biopsy': ['Urinary', 'Prophylaxis'],\n",
       " 'forearm abscess': ['Skin Soft Tissue'],\n",
       " 'hand infection': ['Skin Soft Tissue'],\n",
       " 'hosp acquired pneumonia': ['Respiratory'],\n",
       " 'ie asthma': ['Respiratory'],\n",
       " 'infeciton': ['No Specific Source'],\n",
       " 'infected knee joint': ['Orthopaedic'],\n",
       " 'infected ulcers': ['Skin Soft Tissue'],\n",
       " 'infection ?urinary': ['Urinary', 'Uncertainty'],\n",
       " 'intra abdo': ['Abdominal'],\n",
       " 'intraabdominal infection': ['Abdominal'],\n",
       " 'itching': ['No Specific Source'],\n",
       " 'life long': ['No Specific Source'],\n",
       " 'lung infection': ['Respiratory'],\n",
       " 'myeloma prophylaxis': ['No Specific Source', 'Prophylaxis'],\n",
       " 'neck cellulitis': ['Skin Soft Tissue', 'ENT'],\n",
       " 'necrotising fascitis': ['Skin Soft Tissue'],\n",
       " 'oral candida': ['Other Specific'],\n",
       " 'orbital decompression': ['Other Specific'],\n",
       " 'parapneumonic effusion': ['Respiratory'],\n",
       " 'pcp pneumonia': ['Respiratory'],\n",
       " 'pcp proph': ['Respiratory', 'Prophylaxis'],\n",
       " 'penile infection': ['Skin Soft Tissue'],\n",
       " 'pericarditis': ['Other Specific'],\n",
       " 'positive culture': ['No Specific Source'],\n",
       " 'possible empyema': ['Respiratory', 'Uncertainty'],\n",
       " 'post allograft': ['No Specific Source', 'Prophylaxis'],\n",
       " 'post i+d': ['No Specific Source', 'Prophylaxis'],\n",
       " 'post op bleed': ['No Specific Source', 'Prophylaxis'],\n",
       " 'post operation': ['No Specific Source', 'Prophylaxis'],\n",
       " 'post-op cover': ['No Specific Source', 'Prophylaxis'],\n",
       " 'post-op plan': ['No Specific Source', 'Prophylaxis'],\n",
       " 'pre-septal cellulitis': ['Skin Soft Tissue'],\n",
       " 'pre-thoracoscopy': ['Respiratory', 'Prophylaxis'],\n",
       " 'prokinetics': ['No Specific Source'],\n",
       " 'prophylaxis on chemo': ['No Specific Source', 'Prophylaxis'],\n",
       " 'psa prophylaxis': ['No Specific Source', 'Prophylaxis'],\n",
       " 'psc': ['Abdominal'],\n",
       " 'r hand cellulitis': ['Skin Soft Tissue'],\n",
       " 'raised crp': ['No Specific Source'],\n",
       " 'renal abscess': ['Urinary'],\n",
       " 'right heel ulcer': ['Skin Soft Tissue'],\n",
       " 'sepsis unkown origin': ['No Specific Source', 'Uncertainty'],\n",
       " 'spinal metalwork infectio': ['Orthopaedic', 'Prophylaxis'],\n",
       " 'splenectomy prophylaxis': ['Abdominal', 'Prophylaxis'],\n",
       " 'srom>24hrs': ['Other Specific'],\n",
       " 'stem cell transplant': ['No Specific Source'],\n",
       " 'subphrenic collection': ['Respiratory'],\n",
       " 'superficial skin infectio': ['Skin Soft Tissue'],\n",
       " 'superficial wound infecti': ['Skin Soft Tissue'],\n",
       " 'supraglottitis': ['ENT'],\n",
       " 'surg prophylaxis': ['No Specific Source', 'Prophylaxis'],\n",
       " 'surgical infection': ['No Specific Source', 'Prophylaxis'],\n",
       " 'suspected chorioamnioniti': ['Other Specific', 'Uncertainty'],\n",
       " 'temp spike': ['No Specific Source'],\n",
       " 'tonsillitits': ['ENT'],\n",
       " 'urine/chest infection': ['Urinary', 'Respiratory', 'Uncertainty'],\n",
       " 'uti post op': ['Urinary', 'Prophylaxis'],\n",
       " 'uti prophylaxis': ['Urinary', 'Prophylaxis'],\n",
       " 'uti/lrti': ['Urinary', 'Respiratory', 'Uncertainty'],\n",
       " 'vasculitis': ['Other Specific'],\n",
       " 'worsening cap': ['Respiratory'],\n",
       " 'wound infection prophylax': ['Skin Soft Tissue', 'Prophylaxis'],\n",
       " 'wound prophylaxis': ['Skin Soft Tissue', 'Prophylaxis'],\n",
       " 'wound site infection': ['Skin Soft Tissue']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot long, group by indications and aggregate into list\n",
    "d = (test_subsample\n",
    "     # Pivot to long format and filter out entries with \"0\"\n",
    "    .melt(\n",
    "        id_vars=[\"Indication\"],\n",
    "        value_vars=labels_pretty,\n",
    "        var_name=\"Sources\",\n",
    "        value_name=\"Indicator\")\n",
    "    .query(\"Indicator==1\")\n",
    "    .drop(\"Indicator\", axis=1)\n",
    "    # Aggregate into a list of indications: <Indication> | [<sources>,...]\n",
    "    .groupby(\"Indication\")\n",
    "    .aggregate(list)\n",
    "    # Reshape into a dictionary\n",
    "    .to_dict(\"dict\")\n",
    "    [\"Sources\"]\n",
    ")\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Formatting\n",
    "Format the promts, they consist of three massages per training example: System, User, Assistant.\n",
    "Use the informatin gathered from the few-shot models, ask for a JSON and return a JSON.\n",
    "\n",
    "Future improvements could involve reducing the prompt text count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_finetuning_data(\n",
    "        system_prompt: str, \n",
    "        input_df: pd.DataFrame, \n",
    "        variable_col: str = \"Indication\", \n",
    "        batch_size: int=50\n",
    "        ):\n",
    "    \"\"\"Generate finetuning data in `.jsonl` format.\n",
    "    Create a \"message\" per entry, with three `role`-`content` pairs. One for each input\n",
    "    :param system_prompt: \n",
    "    :param input_data: \n",
    "    :param output_data: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    # --- Preprocess the data \n",
    "    # Split data into chunks\n",
    "    finetune_data_split = input_df.groupby(np.arange(len(input_df)) // batch_size)\n",
    "\n",
    "    # Output fintuning data\n",
    "    training_data = []\n",
    "\n",
    "    for _, chunk in finetune_data_split:\n",
    "        # -- Format the input\n",
    "        chunk_indications = chunk[variable_col]\n",
    "        \n",
    "        # -- Format the output as dictionary/json\n",
    "        chunk_output = {}\n",
    "        for indication, values in chunk.set_index(variable_col).to_dict(orient=\"index\").items():\n",
    "            chunk_output[indication] = [category for category, value in values.items() if value == 1]\n",
    "\n",
    "        # -- Build the training example for the current chunk\n",
    "        training_sample = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt_user_template.render(indications=chunk_indications, categories=labels_pretty),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": json.dumps(chunk_output, indent=4),\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        training_data += [json.dumps(training_sample)]\n",
    "    \n",
    "    return \"\\n\".join(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some metadata\n",
    "time_stamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "batch_size = 10\n",
    "prototype = False\n",
    "\n",
    "train_ft_data = train_df.copy()\n",
    "eval_ft_data = eval_df.copy()\n",
    "proto_var = \"\"\n",
    "\n",
    "# Subset the data if this is a prototype run\n",
    "if prototype:\n",
    "    train_ft_data = train_ft_data.head(1000)\n",
    "    eval_ft_data = eval_ft_data(300)\n",
    "    proto_var = \"-proto\"\n",
    "\n",
    "# Generate finetuning training data\n",
    "finetuning_data_train = generate_finetuning_data(\n",
    "    system_prompt=prompt_system_template.render(categories=labels_pretty),\n",
    "    input_df=train_df,\n",
    "    variable_col=\"Indication\",\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Generate finetuning validation data\n",
    "finetuning_data_val = generate_finetuning_data(\n",
    "    system_prompt=prompt_system_template.render(categories=labels_pretty),\n",
    "    input_df=eval_df,\n",
    "    variable_col=\"Indication\",\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Write the finetuning data to disk\n",
    "training_file_name = f\"finetuning_data_train{proto_var}-b_{batch_size}-{time_stamp}.jsonl\"\n",
    "validation_file_name = f\"finetuning_data_val{proto_var}-b_{batch_size}-{time_stamp}.jsonl\"\n",
    "\n",
    "with open(ft_data_path  / training_file_name, \"w\") as f:\n",
    "    f.write(finetuning_data_train)\n",
    "\n",
    "with open(ft_data_path / validation_file_name, \"w\") as f:\n",
    "    f.write(finetuning_data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate some costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 446, 537\n",
      "mean / median: 497.79411764705884, 498.0\n",
      "p5 / p95: 479.0, 516.1\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 148, 222\n",
      "mean / median: 188.0705882352941, 188.0\n",
      "p5 / p95: 172.0, 203.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~169250 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~507750 tokens\n",
      "Estimated cost based on 8.00$/mio tokens: 4.06$\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # for token counting\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "\n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "dataset = [json.loads(line) for line in finetuning_data_train.split(\"\\n\")]\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "\n",
    "# Calculate cost:\n",
    "cost_per_mio_tokens = 8.00\n",
    "\n",
    "print(f\"Estimated cost based on {cost_per_mio_tokens:.2f}$/mio tokens: \"\n",
    "      f\"{((n_epochs * n_billing_tokens_in_dataset) / (1e6) * cost_per_mio_tokens):.2f}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "def upload_file(file_path):\n",
    "  with open(file_path, \"rb\") as file:\n",
    "    upload_response =client.files.create(\n",
    "      file=file,\n",
    "      purpose=\"fine-tune\"\n",
    "    )\n",
    "  logging.debug(f\"Uploaded file: {upload_response}\")\n",
    "  return upload_response.id\n",
    "\n",
    "training_file_id = upload_file(ft_data_path / training_file_name)\n",
    "validation_file_id = upload_file(ft_data_path / validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Finetuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-7c8L6gZjl8XDc9g8m2dpjilw', created_at=1713207779, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-9JKFMdh9B3qyaM6YrsUMxeyR', result_files=[], status='validating_files', trained_tokens=None, training_file='file-Z4Zvg7GD3LpZrLnZF0aHrP7V', validation_file='file-SI9hkbL8P7wkJWPlqQxGCx2W', user_provided_suffix='full_2-b_10', seed=2105952863, integrations=[])\n"
     ]
    }
   ],
   "source": [
    "run_number = 2  # Increment it each time we apply significant change?\n",
    "run_type = \"proto\" if prototype else \"full\"\n",
    "model_suffix = f\"{run_type}_{run_number}-b_{batch_size}\"\n",
    "\n",
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "  model=model_openai_id,  # Model type (must support JSON output)\n",
    "  training_file=training_file_id,\n",
    "  validation_file=validation_file_id,\n",
    "  suffix=model_suffix,  # Custom model suffix\n",
    "  # seed=42,\n",
    "  hyperparameters={\n",
    "      \"batch_size\": \"auto\",\n",
    "      \"learning_rate_multiplier\": \"auto\",\n",
    "      \"n_epochs\": \"auto\"\n",
    "  }\n",
    ")\n",
    "\n",
    "print(fine_tune_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned model archive:\n",
    "| FT Name      | Type      | Batch Size | Comments FT Dataset                     | Comments Inference                                   |\n",
    "|--------------|-----------|------------|-----------------------------------------|------------------------------------------------------|\n",
    "| proto-b-50   | Full      | 50         |                                         | Prediction loops occasionally                        |\n",
    "| proto-2-b-50 | Full      | 50         | Add linebreaks in the assistant prompt. | Prediction output loops constantly, character limit. |\n",
    "| proto-1-b-10 | Prototype | 10         | Reduce batch size                       | Works, most of the time but breaks sometimes         |\n",
    "| proto-2-b-10 | Prototype | 10         | Remove instructions in user prompt      | Works                                                |\n",
    "| full-1-b-10  | Full      | 10         | Full training data, batch size 10       | Works most of the time, pick checkpoint              |\n",
    "| full-2-b-10  | Full      | 10         | Remove instructions in user prompt er   | Works, reduce number of epochs or pick checkpoint    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the finetuned model\n",
    "Use the defined methods and run the model for the whole dataset, chunk it!\n",
    "Add some smartness for reruns and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data for code development\n",
    "train_pretty = train_df.rename(columns=labels2labels_pretty)[:200]\n",
    "train_pretty_indication = train_pretty.Indication\n",
    "\n",
    "# Without linebreaks\n",
    "ft_model_id = \"ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:proto-b-50:9BkHKxQb\"\n",
    "# With linebreaks\n",
    "ft_model_id = \"ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_completion(input_indications, categories, model_id, chunksize=100, reduce_usage=True):\n",
    "    # Reduce the number of input indications if specified\n",
    "    indications_orig = input_indications.copy()\n",
    "    if reduce_usage:\n",
    "        input_indications.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Variables to store the results & precomute stuff for the while loop\n",
    "    input_df_length = len(input_indications)\n",
    "\n",
    "    cursor = 0\n",
    "    tmp_prediction_df_list = []\n",
    "    prediction_metadata_list = []\n",
    "\n",
    "    # Setup progress bar\n",
    "    with tqdm(total=input_df_length) as p_bar:\n",
    "        # Start batch processing\n",
    "        while cursor < input_df_length:\n",
    "            cursor_end = min(cursor+chunksize, input_df_length)\n",
    "\n",
    "            logging.info(f\"Processing chunk {cursor}:{cursor_end} of {input_df_length}\")\n",
    "\n",
    "            # Subset the dataset\n",
    "            chunk_indications = input_indications.iloc[cursor:cursor_end]\n",
    "\n",
    "            # Render the templates\n",
    "            prompt_user = prompt_user_template.render(indications=chunk_indications, categories=categories)\n",
    "            prompt_system = prompt_system_template.render(categories=categories)\n",
    "\n",
    "            # Request the completion\n",
    "            chat_completion_message, chat_completion_metadata, chat_completion_usage = request_completion(\n",
    "                client=client,\n",
    "                system_prompt=prompt_system, \n",
    "                user_prompt=prompt_user, \n",
    "                model_openai_id=model_id, \n",
    "                max_tokens=None)\n",
    "            # logging.info(f\"Message {chat_completion_message}\")\n",
    "            logging.info(f\"Metadata: {chat_completion_metadata}\")\n",
    "            logging.info(f\"Usage: {chat_completion_usage}\")\n",
    "            \n",
    "            # Check if output is truncated, reduce the maximum chunksize and rerun\n",
    "            if chat_completion_metadata[\"finish_reason\"] != \"stop\":\n",
    "                chunksize = chunksize - 10\n",
    "                logging.warning(f\"Metadata: {chat_completion_metadata}\")\n",
    "                logging.warning(f\"Usage: {chat_completion_usage}\")\n",
    "                logging.warning(f\"Maximum chunksize has been reduced to {chunksize}\")\n",
    "\n",
    "                if chunksize <=0:\n",
    "                    logging.error(f\"The chunksize {chunksize} is not reachable. Please investigate the input\")\n",
    "                    break\n",
    "                \n",
    "                continue\n",
    "\n",
    "            # Save the results and metadata\n",
    "            chat_completion_metadata[\"chunk_start\"] = cursor\n",
    "            chat_completion_metadata[\"chunk_end\"] = cursor_end\n",
    "\n",
    "            tmp_prediction_df_list.append(format_message_to_df(chat_completion_message))\n",
    "            prediction_metadata_list.append(chat_completion_metadata)\n",
    "            \n",
    "            # Show usage and continue to the next chunk\n",
    "            logging.info(f\"Usage: {chat_completion_usage}\")\n",
    "            p_bar.update(chunksize)\n",
    "            cursor += chunksize\n",
    "\n",
    "    # Combine the results\n",
    "    prediction_df = (\n",
    "        # Restore the original order\n",
    "        pd.concat(tmp_prediction_df_list)\n",
    "        .reindex(indications_orig)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    prediction_metadata_df = pd.DataFrame(prediction_metadata_list)\n",
    "\n",
    "    return prediction_df, prediction_metadata_df\n",
    "\n",
    "# run_completion(test_oxford_df[250:300], labels_pretty, ft_model_id, chunksize=50, reduce_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dab59359b14507b967abc032e5bbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/836 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing chunk 0:10 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216039, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 310, 'total_tokens': 490}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 310, 'total_tokens': 490}\n",
      "INFO:root:Processing chunk 10:20 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216044, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 306, 'total_tokens': 486}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 306, 'total_tokens': 486}\n",
      "INFO:root:Processing chunk 20:30 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216051, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 311, 'total_tokens': 485}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 311, 'total_tokens': 485}\n",
      "INFO:root:Processing chunk 30:40 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216055, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 297, 'total_tokens': 477}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 297, 'total_tokens': 477}\n",
      "INFO:root:Processing chunk 40:50 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216058, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 195, 'prompt_tokens': 313, 'total_tokens': 508}\n",
      "INFO:root:Usage: {'completion_tokens': 195, 'prompt_tokens': 313, 'total_tokens': 508}\n",
      "INFO:root:Processing chunk 50:60 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216060, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 309, 'total_tokens': 488}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 309, 'total_tokens': 488}\n",
      "INFO:root:Processing chunk 60:70 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216064, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 176, 'prompt_tokens': 300, 'total_tokens': 476}\n",
      "INFO:root:Usage: {'completion_tokens': 176, 'prompt_tokens': 300, 'total_tokens': 476}\n",
      "INFO:root:Processing chunk 70:80 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216069, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 164, 'prompt_tokens': 300, 'total_tokens': 464}\n",
      "INFO:root:Usage: {'completion_tokens': 164, 'prompt_tokens': 300, 'total_tokens': 464}\n",
      "INFO:root:Processing chunk 80:90 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216072, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 316, 'total_tokens': 505}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 316, 'total_tokens': 505}\n",
      "INFO:root:Processing chunk 90:100 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216075, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 193, 'prompt_tokens': 310, 'total_tokens': 503}\n",
      "INFO:root:Usage: {'completion_tokens': 193, 'prompt_tokens': 310, 'total_tokens': 503}\n",
      "INFO:root:Processing chunk 100:110 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216078, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 308, 'total_tokens': 493}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 308, 'total_tokens': 493}\n",
      "INFO:root:Processing chunk 110:120 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216081, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 309, 'total_tokens': 513}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 309, 'total_tokens': 513}\n",
      "INFO:root:Processing chunk 120:130 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216084, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 212, 'prompt_tokens': 314, 'total_tokens': 526}\n",
      "INFO:root:Usage: {'completion_tokens': 212, 'prompt_tokens': 314, 'total_tokens': 526}\n",
      "INFO:root:Processing chunk 130:140 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216088, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 296, 'total_tokens': 482}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 296, 'total_tokens': 482}\n",
      "INFO:root:Processing chunk 140:150 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216091, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 306, 'total_tokens': 502}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 306, 'total_tokens': 502}\n",
      "INFO:root:Processing chunk 150:160 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216095, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 307, 'total_tokens': 493}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 307, 'total_tokens': 493}\n",
      "INFO:root:Processing chunk 160:170 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216098, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 215, 'prompt_tokens': 315, 'total_tokens': 530}\n",
      "INFO:root:Usage: {'completion_tokens': 215, 'prompt_tokens': 315, 'total_tokens': 530}\n",
      "INFO:root:Processing chunk 170:180 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216101, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 213, 'prompt_tokens': 311, 'total_tokens': 524}\n",
      "INFO:root:Usage: {'completion_tokens': 213, 'prompt_tokens': 311, 'total_tokens': 524}\n",
      "INFO:root:Processing chunk 180:190 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216105, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 170, 'prompt_tokens': 305, 'total_tokens': 475}\n",
      "INFO:root:Usage: {'completion_tokens': 170, 'prompt_tokens': 305, 'total_tokens': 475}\n",
      "INFO:root:Processing chunk 190:200 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216108, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 310, 'total_tokens': 499}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 310, 'total_tokens': 499}\n",
      "INFO:root:Processing chunk 200:210 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216112, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 315, 'total_tokens': 512}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 315, 'total_tokens': 512}\n",
      "INFO:root:Processing chunk 210:220 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216115, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 305, 'total_tokens': 494}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 305, 'total_tokens': 494}\n",
      "INFO:root:Processing chunk 220:230 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216118, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 167, 'prompt_tokens': 309, 'total_tokens': 476}\n",
      "INFO:root:Usage: {'completion_tokens': 167, 'prompt_tokens': 309, 'total_tokens': 476}\n",
      "INFO:root:Processing chunk 230:240 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216121, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 183, 'prompt_tokens': 308, 'total_tokens': 491}\n",
      "INFO:root:Usage: {'completion_tokens': 183, 'prompt_tokens': 308, 'total_tokens': 491}\n",
      "INFO:root:Processing chunk 240:250 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216123, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 173, 'prompt_tokens': 308, 'total_tokens': 481}\n",
      "INFO:root:Usage: {'completion_tokens': 173, 'prompt_tokens': 308, 'total_tokens': 481}\n",
      "INFO:root:Processing chunk 250:260 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216126, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 190, 'prompt_tokens': 310, 'total_tokens': 500}\n",
      "INFO:root:Usage: {'completion_tokens': 190, 'prompt_tokens': 310, 'total_tokens': 500}\n",
      "INFO:root:Processing chunk 260:270 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216129, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 205, 'prompt_tokens': 315, 'total_tokens': 520}\n",
      "INFO:root:Usage: {'completion_tokens': 205, 'prompt_tokens': 315, 'total_tokens': 520}\n",
      "INFO:root:Processing chunk 270:280 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216132, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 206, 'prompt_tokens': 320, 'total_tokens': 526}\n",
      "INFO:root:Usage: {'completion_tokens': 206, 'prompt_tokens': 320, 'total_tokens': 526}\n",
      "INFO:root:Processing chunk 280:290 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216135, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 318, 'total_tokens': 522}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 318, 'total_tokens': 522}\n",
      "INFO:root:Processing chunk 290:300 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216138, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 203, 'prompt_tokens': 308, 'total_tokens': 511}\n",
      "INFO:root:Usage: {'completion_tokens': 203, 'prompt_tokens': 308, 'total_tokens': 511}\n",
      "INFO:root:Processing chunk 300:310 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216141, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 202, 'prompt_tokens': 312, 'total_tokens': 514}\n",
      "INFO:root:Usage: {'completion_tokens': 202, 'prompt_tokens': 312, 'total_tokens': 514}\n",
      "INFO:root:Processing chunk 310:320 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216145, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 303, 'total_tokens': 492}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 303, 'total_tokens': 492}\n",
      "INFO:root:Processing chunk 320:330 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216148, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 311, 'total_tokens': 503}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 311, 'total_tokens': 503}\n",
      "INFO:root:Processing chunk 330:340 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216151, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 307, 'total_tokens': 496}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 307, 'total_tokens': 496}\n",
      "INFO:root:Processing chunk 340:350 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216154, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 169, 'prompt_tokens': 302, 'total_tokens': 471}\n",
      "INFO:root:Usage: {'completion_tokens': 169, 'prompt_tokens': 302, 'total_tokens': 471}\n",
      "INFO:root:Processing chunk 350:360 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216158, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 306, 'total_tokens': 498}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 306, 'total_tokens': 498}\n",
      "INFO:root:Processing chunk 360:370 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216162, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 318, 'total_tokens': 504}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 318, 'total_tokens': 504}\n",
      "INFO:root:Processing chunk 370:380 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216165, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 311, 'total_tokens': 503}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 311, 'total_tokens': 503}\n",
      "INFO:root:Processing chunk 380:390 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216168, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 170, 'prompt_tokens': 301, 'total_tokens': 471}\n",
      "INFO:root:Usage: {'completion_tokens': 170, 'prompt_tokens': 301, 'total_tokens': 471}\n",
      "INFO:root:Processing chunk 390:400 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216171, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 304, 'total_tokens': 496}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 304, 'total_tokens': 496}\n",
      "INFO:root:Processing chunk 400:410 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216175, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 314, 'total_tokens': 488}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 314, 'total_tokens': 488}\n",
      "INFO:root:Processing chunk 410:420 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216177, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 300, 'total_tokens': 474}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 300, 'total_tokens': 474}\n",
      "INFO:root:Processing chunk 420:430 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216180, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 314, 'total_tokens': 498}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 314, 'total_tokens': 498}\n",
      "INFO:root:Processing chunk 430:440 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216183, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 170, 'prompt_tokens': 313, 'total_tokens': 483}\n",
      "INFO:root:Usage: {'completion_tokens': 170, 'prompt_tokens': 313, 'total_tokens': 483}\n",
      "INFO:root:Processing chunk 440:450 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216186, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 205, 'prompt_tokens': 312, 'total_tokens': 517}\n",
      "INFO:root:Usage: {'completion_tokens': 205, 'prompt_tokens': 312, 'total_tokens': 517}\n",
      "INFO:root:Processing chunk 450:460 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216190, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 310, 'total_tokens': 506}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 310, 'total_tokens': 506}\n",
      "INFO:root:Processing chunk 460:470 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216192, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 163, 'prompt_tokens': 315, 'total_tokens': 478}\n",
      "INFO:root:Usage: {'completion_tokens': 163, 'prompt_tokens': 315, 'total_tokens': 478}\n",
      "INFO:root:Processing chunk 470:480 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216195, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 218, 'prompt_tokens': 318, 'total_tokens': 536}\n",
      "INFO:root:Usage: {'completion_tokens': 218, 'prompt_tokens': 318, 'total_tokens': 536}\n",
      "INFO:root:Processing chunk 480:490 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216198, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 310, 'total_tokens': 494}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 310, 'total_tokens': 494}\n",
      "INFO:root:Processing chunk 490:500 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216201, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 212, 'prompt_tokens': 314, 'total_tokens': 526}\n",
      "INFO:root:Usage: {'completion_tokens': 212, 'prompt_tokens': 314, 'total_tokens': 526}\n",
      "INFO:root:Processing chunk 500:510 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216204, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 309, 'total_tokens': 498}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 309, 'total_tokens': 498}\n",
      "INFO:root:Processing chunk 510:520 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216207, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 310, 'total_tokens': 499}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 310, 'total_tokens': 499}\n",
      "INFO:root:Processing chunk 520:530 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216209, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 191, 'prompt_tokens': 311, 'total_tokens': 502}\n",
      "INFO:root:Usage: {'completion_tokens': 191, 'prompt_tokens': 311, 'total_tokens': 502}\n",
      "INFO:root:Processing chunk 530:540 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216212, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 206, 'prompt_tokens': 320, 'total_tokens': 526}\n",
      "INFO:root:Usage: {'completion_tokens': 206, 'prompt_tokens': 320, 'total_tokens': 526}\n",
      "INFO:root:Processing chunk 540:550 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216215, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 198, 'prompt_tokens': 312, 'total_tokens': 510}\n",
      "INFO:root:Usage: {'completion_tokens': 198, 'prompt_tokens': 312, 'total_tokens': 510}\n",
      "INFO:root:Processing chunk 550:560 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216217, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 306, 'total_tokens': 486}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 306, 'total_tokens': 486}\n",
      "INFO:root:Processing chunk 560:570 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216220, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 171, 'prompt_tokens': 305, 'total_tokens': 476}\n",
      "INFO:root:Usage: {'completion_tokens': 171, 'prompt_tokens': 305, 'total_tokens': 476}\n",
      "INFO:root:Processing chunk 570:580 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216223, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 208, 'prompt_tokens': 306, 'total_tokens': 514}\n",
      "INFO:root:Usage: {'completion_tokens': 208, 'prompt_tokens': 306, 'total_tokens': 514}\n",
      "INFO:root:Processing chunk 580:590 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216225, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 308, 'total_tokens': 496}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 308, 'total_tokens': 496}\n",
      "INFO:root:Processing chunk 590:600 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216229, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 169, 'prompt_tokens': 299, 'total_tokens': 468}\n",
      "INFO:root:Usage: {'completion_tokens': 169, 'prompt_tokens': 299, 'total_tokens': 468}\n",
      "INFO:root:Processing chunk 600:610 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216231, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 316, 'total_tokens': 508}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 316, 'total_tokens': 508}\n",
      "INFO:root:Processing chunk 610:620 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216235, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 315, 'total_tokens': 519}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 315, 'total_tokens': 519}\n",
      "INFO:root:Processing chunk 620:630 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216237, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 178, 'prompt_tokens': 317, 'total_tokens': 495}\n",
      "INFO:root:Usage: {'completion_tokens': 178, 'prompt_tokens': 317, 'total_tokens': 495}\n",
      "INFO:root:Processing chunk 630:640 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216240, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 312, 'total_tokens': 509}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 312, 'total_tokens': 509}\n",
      "INFO:root:Processing chunk 640:650 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216243, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 191, 'prompt_tokens': 310, 'total_tokens': 501}\n",
      "INFO:root:Usage: {'completion_tokens': 191, 'prompt_tokens': 310, 'total_tokens': 501}\n",
      "INFO:root:Processing chunk 650:660 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216246, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 305, 'total_tokens': 485}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 305, 'total_tokens': 485}\n",
      "INFO:root:Processing chunk 660:670 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216249, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 316, 'total_tokens': 512}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 316, 'total_tokens': 512}\n",
      "INFO:root:Processing chunk 670:680 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216252, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 193, 'prompt_tokens': 309, 'total_tokens': 502}\n",
      "INFO:root:Usage: {'completion_tokens': 193, 'prompt_tokens': 309, 'total_tokens': 502}\n",
      "INFO:root:Processing chunk 680:690 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216256, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 187, 'prompt_tokens': 314, 'total_tokens': 501}\n",
      "INFO:root:Usage: {'completion_tokens': 187, 'prompt_tokens': 314, 'total_tokens': 501}\n",
      "INFO:root:Processing chunk 690:700 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216259, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 206, 'prompt_tokens': 309, 'total_tokens': 515}\n",
      "INFO:root:Usage: {'completion_tokens': 206, 'prompt_tokens': 309, 'total_tokens': 515}\n",
      "INFO:root:Processing chunk 700:710 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216262, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 202, 'prompt_tokens': 309, 'total_tokens': 511}\n",
      "INFO:root:Usage: {'completion_tokens': 202, 'prompt_tokens': 309, 'total_tokens': 511}\n",
      "INFO:root:Processing chunk 710:720 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216266, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 218, 'prompt_tokens': 311, 'total_tokens': 529}\n",
      "INFO:root:Usage: {'completion_tokens': 218, 'prompt_tokens': 311, 'total_tokens': 529}\n",
      "INFO:root:Processing chunk 720:730 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216269, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 172, 'prompt_tokens': 316, 'total_tokens': 488}\n",
      "INFO:root:Usage: {'completion_tokens': 172, 'prompt_tokens': 316, 'total_tokens': 488}\n",
      "INFO:root:Processing chunk 730:740 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216272, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 305, 'total_tokens': 484}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 305, 'total_tokens': 484}\n",
      "INFO:root:Processing chunk 740:750 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216275, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 208, 'prompt_tokens': 317, 'total_tokens': 525}\n",
      "INFO:root:Usage: {'completion_tokens': 208, 'prompt_tokens': 317, 'total_tokens': 525}\n",
      "INFO:root:Processing chunk 750:760 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216278, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 172, 'prompt_tokens': 308, 'total_tokens': 480}\n",
      "INFO:root:Usage: {'completion_tokens': 172, 'prompt_tokens': 308, 'total_tokens': 480}\n",
      "INFO:root:Processing chunk 760:770 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216281, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 299, 'total_tokens': 479}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 299, 'total_tokens': 479}\n",
      "INFO:root:Processing chunk 770:780 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216283, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 311, 'total_tokens': 495}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 311, 'total_tokens': 495}\n",
      "INFO:root:Processing chunk 780:790 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216286, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 315, 'total_tokens': 503}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 315, 'total_tokens': 503}\n",
      "INFO:root:Processing chunk 790:800 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216288, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 311, 'total_tokens': 495}\n",
      "INFO:root:Usage: {'completion_tokens': 184, 'prompt_tokens': 311, 'total_tokens': 495}\n",
      "INFO:root:Processing chunk 800:810 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216292, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 182, 'prompt_tokens': 304, 'total_tokens': 486}\n",
      "INFO:root:Usage: {'completion_tokens': 182, 'prompt_tokens': 304, 'total_tokens': 486}\n",
      "INFO:root:Processing chunk 810:820 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216295, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 164, 'prompt_tokens': 304, 'total_tokens': 468}\n",
      "INFO:root:Usage: {'completion_tokens': 164, 'prompt_tokens': 304, 'total_tokens': 468}\n",
      "INFO:root:Processing chunk 820:830 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216297, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 182, 'prompt_tokens': 309, 'total_tokens': 491}\n",
      "INFO:root:Usage: {'completion_tokens': 182, 'prompt_tokens': 309, 'total_tokens': 491}\n",
      "INFO:root:Processing chunk 830:836 of 836\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216299, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 101, 'prompt_tokens': 283, 'total_tokens': 384}\n",
      "INFO:root:Usage: {'completion_tokens': 101, 'prompt_tokens': 283, 'total_tokens': 384}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in predictions: set()\n",
      "Not in train: set()\n",
      "({'F1-Score': 0.9479073922839666},           Urinary  Respiratory  Abdominal  Neurological  Skin Soft Tissue  \\\n",
      "F1-Score     0.98         0.97       0.95          0.93              0.83   \n",
      "\n",
      "          ENT  Orthopaedic  Other Specific  No Specific Source  Prophylaxis  \\\n",
      "F1-Score  0.8         0.95            0.77                0.97         0.97   \n",
      "\n",
      "          Uncertainty  Not Informative  \n",
      "F1-Score         0.92             0.99  )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3231f7083ce0418a9c9cb9446923b605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/587 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing chunk 0:10 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216301, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 291, 'total_tokens': 465}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 291, 'total_tokens': 465}\n",
      "INFO:root:Processing chunk 10:20 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216304, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 308, 'total_tokens': 497}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 308, 'total_tokens': 497}\n",
      "INFO:root:Processing chunk 20:30 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216306, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 304, 'total_tokens': 492}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 304, 'total_tokens': 492}\n",
      "INFO:root:Processing chunk 30:40 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216309, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 315, 'total_tokens': 512}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 315, 'total_tokens': 512}\n",
      "INFO:root:Processing chunk 40:50 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216312, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 198, 'prompt_tokens': 306, 'total_tokens': 504}\n",
      "INFO:root:Usage: {'completion_tokens': 198, 'prompt_tokens': 306, 'total_tokens': 504}\n",
      "INFO:root:Processing chunk 50:60 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216314, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 209, 'prompt_tokens': 316, 'total_tokens': 525}\n",
      "INFO:root:Usage: {'completion_tokens': 209, 'prompt_tokens': 316, 'total_tokens': 525}\n",
      "INFO:root:Processing chunk 60:70 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216318, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 307, 'total_tokens': 481}\n",
      "INFO:root:Usage: {'completion_tokens': 174, 'prompt_tokens': 307, 'total_tokens': 481}\n",
      "INFO:root:Processing chunk 70:80 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216320, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 187, 'prompt_tokens': 313, 'total_tokens': 500}\n",
      "INFO:root:Usage: {'completion_tokens': 187, 'prompt_tokens': 313, 'total_tokens': 500}\n",
      "INFO:root:Processing chunk 80:90 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216324, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 205, 'prompt_tokens': 310, 'total_tokens': 515}\n",
      "INFO:root:Usage: {'completion_tokens': 205, 'prompt_tokens': 310, 'total_tokens': 515}\n",
      "INFO:root:Processing chunk 90:100 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216327, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 198, 'prompt_tokens': 305, 'total_tokens': 503}\n",
      "INFO:root:Usage: {'completion_tokens': 198, 'prompt_tokens': 305, 'total_tokens': 503}\n",
      "INFO:root:Processing chunk 100:110 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216331, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 165, 'prompt_tokens': 301, 'total_tokens': 466}\n",
      "INFO:root:Usage: {'completion_tokens': 165, 'prompt_tokens': 301, 'total_tokens': 466}\n",
      "INFO:root:Processing chunk 110:120 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216334, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 310, 'total_tokens': 490}\n",
      "INFO:root:Usage: {'completion_tokens': 180, 'prompt_tokens': 310, 'total_tokens': 490}\n",
      "INFO:root:Processing chunk 120:130 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216337, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 216, 'prompt_tokens': 316, 'total_tokens': 532}\n",
      "INFO:root:Usage: {'completion_tokens': 216, 'prompt_tokens': 316, 'total_tokens': 532}\n",
      "INFO:root:Processing chunk 130:140 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216339, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 172, 'prompt_tokens': 308, 'total_tokens': 480}\n",
      "INFO:root:Usage: {'completion_tokens': 172, 'prompt_tokens': 308, 'total_tokens': 480}\n",
      "INFO:root:Processing chunk 140:150 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216341, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 318, 'total_tokens': 522}\n",
      "INFO:root:Usage: {'completion_tokens': 204, 'prompt_tokens': 318, 'total_tokens': 522}\n",
      "INFO:root:Processing chunk 150:160 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216344, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 309, 'total_tokens': 497}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 309, 'total_tokens': 497}\n",
      "INFO:root:Processing chunk 160:170 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216350, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 209, 'prompt_tokens': 313, 'total_tokens': 522}\n",
      "INFO:root:Usage: {'completion_tokens': 209, 'prompt_tokens': 313, 'total_tokens': 522}\n",
      "INFO:root:Processing chunk 170:180 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216353, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 178, 'prompt_tokens': 311, 'total_tokens': 489}\n",
      "INFO:root:Usage: {'completion_tokens': 178, 'prompt_tokens': 311, 'total_tokens': 489}\n",
      "INFO:root:Processing chunk 180:190 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216356, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 201, 'prompt_tokens': 309, 'total_tokens': 510}\n",
      "INFO:root:Usage: {'completion_tokens': 201, 'prompt_tokens': 309, 'total_tokens': 510}\n",
      "INFO:root:Processing chunk 190:200 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216360, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 177, 'prompt_tokens': 310, 'total_tokens': 487}\n",
      "INFO:root:Usage: {'completion_tokens': 177, 'prompt_tokens': 310, 'total_tokens': 487}\n",
      "INFO:root:Processing chunk 200:210 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216362, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 303, 'total_tokens': 488}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 303, 'total_tokens': 488}\n",
      "INFO:root:Processing chunk 210:220 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216365, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 303, 'total_tokens': 488}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 303, 'total_tokens': 488}\n",
      "INFO:root:Processing chunk 220:230 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216368, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 308, 'total_tokens': 487}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 308, 'total_tokens': 487}\n",
      "INFO:root:Processing chunk 230:240 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216371, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 195, 'prompt_tokens': 311, 'total_tokens': 506}\n",
      "INFO:root:Usage: {'completion_tokens': 195, 'prompt_tokens': 311, 'total_tokens': 506}\n",
      "INFO:root:Processing chunk 240:250 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216373, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 187, 'prompt_tokens': 308, 'total_tokens': 495}\n",
      "INFO:root:Usage: {'completion_tokens': 187, 'prompt_tokens': 308, 'total_tokens': 495}\n",
      "INFO:root:Processing chunk 250:260 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216376, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 306, 'total_tokens': 485}\n",
      "INFO:root:Usage: {'completion_tokens': 179, 'prompt_tokens': 306, 'total_tokens': 485}\n",
      "INFO:root:Processing chunk 260:270 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216378, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 299, 'total_tokens': 495}\n",
      "INFO:root:Usage: {'completion_tokens': 196, 'prompt_tokens': 299, 'total_tokens': 495}\n",
      "INFO:root:Processing chunk 270:280 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216381, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 194, 'prompt_tokens': 319, 'total_tokens': 513}\n",
      "INFO:root:Usage: {'completion_tokens': 194, 'prompt_tokens': 319, 'total_tokens': 513}\n",
      "INFO:root:Processing chunk 280:290 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216386, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 221, 'prompt_tokens': 327, 'total_tokens': 548}\n",
      "INFO:root:Usage: {'completion_tokens': 221, 'prompt_tokens': 327, 'total_tokens': 548}\n",
      "INFO:root:Processing chunk 290:300 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216388, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 214, 'prompt_tokens': 316, 'total_tokens': 530}\n",
      "INFO:root:Usage: {'completion_tokens': 214, 'prompt_tokens': 316, 'total_tokens': 530}\n",
      "INFO:root:Processing chunk 300:310 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216392, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 308, 'total_tokens': 496}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 308, 'total_tokens': 496}\n",
      "INFO:root:Processing chunk 310:320 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216395, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 309, 'total_tokens': 497}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 309, 'total_tokens': 497}\n",
      "INFO:root:Processing chunk 320:330 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216398, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 175, 'prompt_tokens': 303, 'total_tokens': 478}\n",
      "INFO:root:Usage: {'completion_tokens': 175, 'prompt_tokens': 303, 'total_tokens': 478}\n",
      "INFO:root:Processing chunk 330:340 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216401, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 190, 'prompt_tokens': 310, 'total_tokens': 500}\n",
      "INFO:root:Usage: {'completion_tokens': 190, 'prompt_tokens': 310, 'total_tokens': 500}\n",
      "INFO:root:Processing chunk 340:350 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216405, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 190, 'prompt_tokens': 308, 'total_tokens': 498}\n",
      "INFO:root:Usage: {'completion_tokens': 190, 'prompt_tokens': 308, 'total_tokens': 498}\n",
      "INFO:root:Processing chunk 350:360 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216407, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 210, 'prompt_tokens': 330, 'total_tokens': 540}\n",
      "INFO:root:Usage: {'completion_tokens': 210, 'prompt_tokens': 330, 'total_tokens': 540}\n",
      "INFO:root:Processing chunk 360:370 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216411, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 316, 'total_tokens': 508}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 316, 'total_tokens': 508}\n",
      "INFO:root:Processing chunk 370:380 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216413, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 181, 'prompt_tokens': 305, 'total_tokens': 486}\n",
      "INFO:root:Usage: {'completion_tokens': 181, 'prompt_tokens': 305, 'total_tokens': 486}\n",
      "INFO:root:Processing chunk 380:390 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216416, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 165, 'prompt_tokens': 301, 'total_tokens': 466}\n",
      "INFO:root:Usage: {'completion_tokens': 165, 'prompt_tokens': 301, 'total_tokens': 466}\n",
      "INFO:root:Processing chunk 390:400 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216419, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 316, 'total_tokens': 513}\n",
      "INFO:root:Usage: {'completion_tokens': 197, 'prompt_tokens': 316, 'total_tokens': 513}\n",
      "INFO:root:Processing chunk 400:410 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216421, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 207, 'prompt_tokens': 315, 'total_tokens': 522}\n",
      "INFO:root:Usage: {'completion_tokens': 207, 'prompt_tokens': 315, 'total_tokens': 522}\n",
      "INFO:root:Processing chunk 410:420 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216424, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 305, 'total_tokens': 494}\n",
      "INFO:root:Usage: {'completion_tokens': 189, 'prompt_tokens': 305, 'total_tokens': 494}\n",
      "INFO:root:Processing chunk 420:430 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216427, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 175, 'prompt_tokens': 307, 'total_tokens': 482}\n",
      "INFO:root:Usage: {'completion_tokens': 175, 'prompt_tokens': 307, 'total_tokens': 482}\n",
      "INFO:root:Processing chunk 430:440 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216429, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 173, 'prompt_tokens': 302, 'total_tokens': 475}\n",
      "INFO:root:Usage: {'completion_tokens': 173, 'prompt_tokens': 302, 'total_tokens': 475}\n",
      "INFO:root:Processing chunk 440:450 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216432, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 212, 'prompt_tokens': 317, 'total_tokens': 529}\n",
      "INFO:root:Usage: {'completion_tokens': 212, 'prompt_tokens': 317, 'total_tokens': 529}\n",
      "INFO:root:Processing chunk 450:460 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216434, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 312, 'total_tokens': 498}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 312, 'total_tokens': 498}\n",
      "INFO:root:Processing chunk 460:470 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216439, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 209, 'prompt_tokens': 320, 'total_tokens': 529}\n",
      "INFO:root:Usage: {'completion_tokens': 209, 'prompt_tokens': 320, 'total_tokens': 529}\n",
      "INFO:root:Processing chunk 470:480 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216442, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 234, 'prompt_tokens': 329, 'total_tokens': 563}\n",
      "INFO:root:Usage: {'completion_tokens': 234, 'prompt_tokens': 329, 'total_tokens': 563}\n",
      "INFO:root:Processing chunk 480:490 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216445, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 316, 'total_tokens': 508}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 316, 'total_tokens': 508}\n",
      "INFO:root:Processing chunk 490:500 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216448, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 316, 'total_tokens': 501}\n",
      "INFO:root:Usage: {'completion_tokens': 185, 'prompt_tokens': 316, 'total_tokens': 501}\n",
      "INFO:root:Processing chunk 500:510 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216451, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 216, 'prompt_tokens': 318, 'total_tokens': 534}\n",
      "INFO:root:Usage: {'completion_tokens': 216, 'prompt_tokens': 318, 'total_tokens': 534}\n",
      "INFO:root:Processing chunk 510:520 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216455, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 323, 'total_tokens': 511}\n",
      "INFO:root:Usage: {'completion_tokens': 188, 'prompt_tokens': 323, 'total_tokens': 511}\n",
      "INFO:root:Processing chunk 520:530 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216459, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 171, 'prompt_tokens': 306, 'total_tokens': 477}\n",
      "INFO:root:Usage: {'completion_tokens': 171, 'prompt_tokens': 306, 'total_tokens': 477}\n",
      "INFO:root:Processing chunk 530:540 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216461, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 178, 'prompt_tokens': 312, 'total_tokens': 490}\n",
      "INFO:root:Usage: {'completion_tokens': 178, 'prompt_tokens': 312, 'total_tokens': 490}\n",
      "INFO:root:Processing chunk 540:550 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216464, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 316, 'total_tokens': 502}\n",
      "INFO:root:Usage: {'completion_tokens': 186, 'prompt_tokens': 316, 'total_tokens': 502}\n",
      "INFO:root:Processing chunk 550:560 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216467, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 320, 'total_tokens': 512}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 320, 'total_tokens': 512}\n",
      "INFO:root:Processing chunk 560:570 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216470, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 194, 'prompt_tokens': 314, 'total_tokens': 508}\n",
      "INFO:root:Usage: {'completion_tokens': 194, 'prompt_tokens': 314, 'total_tokens': 508}\n",
      "INFO:root:Processing chunk 570:580 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216473, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 311, 'total_tokens': 503}\n",
      "INFO:root:Usage: {'completion_tokens': 192, 'prompt_tokens': 311, 'total_tokens': 503}\n",
      "INFO:root:Processing chunk 580:587 of 587\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Metadata: {'model': 'ft:gpt-3.5-turbo-0125:university-of-oxford-bdi:full-2-b-10:9EMoQZuO:ckpt-step-680', 'created': 1713216475, 'finish_reason': 'stop', 'system_fingerprint': 'fp_c96c0eb6b3'}\n",
      "INFO:root:Usage: {'completion_tokens': 154, 'prompt_tokens': 301, 'total_tokens': 455}\n",
      "INFO:root:Usage: {'completion_tokens': 154, 'prompt_tokens': 301, 'total_tokens': 455}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in predictions: set()\n",
      "Not in train: set()\n",
      "({'F1-Score': 0.9666276619996864},           Urinary  Respiratory  Abdominal  Neurological  Skin Soft Tissue  \\\n",
      "F1-Score     0.98         0.98       0.95           1.0              0.91   \n",
      "\n",
      "           ENT  Orthopaedic  Other Specific  No Specific Source  Prophylaxis  \\\n",
      "F1-Score  0.81          0.9             0.7                0.98         0.96   \n",
      "\n",
      "          Uncertainty  Not Informative  \n",
      "F1-Score         0.95              1.0  )\n"
     ]
    }
   ],
   "source": [
    "locations_data = {\n",
    "    \"Oxford\": test_oxford_df,\n",
    "    \"Banbury\": test_banbury_df\n",
    "}\n",
    "\n",
    "# locations_data = {\n",
    "#     \"Proto\": train_pretty\n",
    "# }\n",
    "\n",
    "for location, data in locations_data.items():\n",
    "    # Run completion/prediction\n",
    "    prediction_df, prediction_metadata_df = run_completion(\n",
    "        data.Indication, \n",
    "        labels_pretty,\n",
    "        model_id=ft_model_id,\n",
    "        chunksize=10, \n",
    "        reduce_usage=True\n",
    "        )\n",
    "\n",
    "    # Write the results to file\n",
    "    prediction_df.to_csv(\n",
    "        export_path / f\"predictions_ft_{location}.csv\"\n",
    "    )\n",
    "\n",
    "    prediction_metadata_df.to_csv(\n",
    "        export_path / f\"prediction_metadata_ft_{location}.csv\"\n",
    "    )\n",
    "\n",
    "    # Check for discrepancies between datasets\n",
    "    print(\"Not in predictions:\", set(data.Indication) - set(prediction_df.Indication))\n",
    "    print(\"Not in train:\", set(prediction_df.Indication) - set(data.Indication))\n",
    "\n",
    "    # Calculate the scores\n",
    "    print(score_response(prediction_df.fillna(0), data, labels_pretty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some example messages to try out on the playground (interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_user = prompt_user_template.render(indications=test_oxford_df[640:650].Indication, categories=labels_pretty)\n",
    "prompt_system = prompt_system_template.render(categories=labels_pretty)\n",
    "\n",
    "print(prompt_system)\n",
    "print(prompt_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
